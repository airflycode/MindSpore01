{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leNet 5 模型\n",
    "\n",
    "导入回调函数以保存网络生成文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mindspore.nn as nn\n",
    "from mindspore.train import Model\n",
    "\n",
    "from mindvision.classification.dataset import Mnist\n",
    "from mindvision.classification.models import lenet\n",
    "from mindvision.engine.callback import LossMonitor\n",
    "\n",
    "epochs = 10  # 训练轮次\n",
    "\n",
    "# 1. 构建数据集\n",
    "# download_train = Mnist(path=\"./mnist\", split=\"train\", batch_size=32, repeat_num=1, shuffle=True, resize=32, download=True)\n",
    "# dataset_train = download_train.run()\n",
    "\n",
    "# 2. 定义神经网络\n",
    "network = lenet(num_classes=10, pretrained=False)\n",
    "# 3.1 定义损失函数\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "# 3.2 定义优化器函数\n",
    "net_opt = nn.Momentum(network.trainable_params(), learning_rate=0.01, momentum=0.9)\n",
    "# 3.3 初始化模型参数\n",
    "model = Model(network, loss_fn=net_loss, optimizer=net_opt, metrics={'accuracy'})\n",
    "\n",
    "# 4. 对神经网络执行训练\n",
    "# model.train(epochs, dataset_train, callbacks=[LossMonitor(0.01, 1875)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv1.weight', Parameter (name=conv1.weight, shape=(6, 1, 5, 5), dtype=Float32, requires_grad=True))\n",
      "('conv2.weight', Parameter (name=conv2.weight, shape=(16, 6, 5, 5), dtype=Float32, requires_grad=True))\n",
      "('fc1.weight', Parameter (name=fc1.weight, shape=(120, 256), dtype=Float32, requires_grad=True))\n",
      "('fc1.bias', Parameter (name=fc1.bias, shape=(120,), dtype=Float32, requires_grad=True))\n",
      "('fc2.weight', Parameter (name=fc2.weight, shape=(84, 120), dtype=Float32, requires_grad=True))\n",
      "('fc2.bias', Parameter (name=fc2.bias, shape=(84,), dtype=Float32, requires_grad=True))\n",
      "('fc3.weight', Parameter (name=fc3.weight, shape=(10, 84), dtype=Float32, requires_grad=True))\n",
      "('fc3.bias', Parameter (name=fc3.bias, shape=(10,), dtype=Float32, requires_grad=True))\n",
      "\n",
      "\n",
      "Parameter (name=conv1.weight, shape=(6, 1, 5, 5), dtype=Float32, requires_grad=True)\n",
      "Parameter (name=conv2.weight, shape=(16, 6, 5, 5), dtype=Float32, requires_grad=True)\n",
      "Parameter (name=fc1.weight, shape=(120, 256), dtype=Float32, requires_grad=True)\n",
      "Parameter (name=fc1.bias, shape=(120,), dtype=Float32, requires_grad=True)\n",
      "Parameter (name=fc2.weight, shape=(84, 120), dtype=Float32, requires_grad=True)\n",
      "Parameter (name=fc2.bias, shape=(84,), dtype=Float32, requires_grad=True)\n",
      "Parameter (name=fc3.weight, shape=(10, 84), dtype=Float32, requires_grad=True)\n",
      "Parameter (name=fc3.bias, shape=(10,), dtype=Float32, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor,Model\n",
    "from mindspore import  dtype as mstype\n",
    "from mindspore.train.callback import LossMonitor\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "import mindspore.dataset as ds\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='MindSpore LeNet Example')\n",
    "parser.add_argument('--device_target', type=str, default=\"CPU\", choices=['Ascend', 'GPU', 'CPU'])\n",
    "\n",
    "\n",
    "DATA_DIR = \"./datasets/MNIST_Data/train\"\n",
    "# DATA_DIR = \"./datasets/cifar-10-batches-bin/train\"\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "#采样器\n",
    "sampler = ds.SequentialSampler(num_samples=5)\n",
    "\n",
    "# dataset = ds.Cifar100Dataset(DATA_DIR,sampler=sampler)\n",
    "\n",
    "dataset = ds.MnistDataset(DATA_DIR,sampler=sampler) #这个是MNIST数据集\n",
    "# dataset = ds.Cifar10Dataset(DATA_DIR,sampler=sampler) #这个是Cifar10数据集\n",
    "\n",
    "class LeNet5(nn.Cell):\n",
    "    def __init__(self,num_class=10,num_channel = 1):\n",
    "    # 初始化网络\n",
    "        super(LeNet5,self).__init__()\n",
    "        # 定义所需要的运算\n",
    "        self.conv1 = nn.Conv2d(num_channel,6,5,pad_mode='valid') # 卷积\n",
    "        self.conv2 = nn.Conv2d(6,16,5,pad_mode='valid')\n",
    "        self.fc1 = nn.Dense(256,120) # 全连接层\n",
    "        # self.fc1 = nn.Dense(16*5*5,120) # 全连接层\n",
    "        self.fc2 = nn.Dense(120,84)\n",
    "        self.fc3 = nn.Dense(84,num_class)\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2,stride=2)# 最大池化-降采样\n",
    "        self.relu = nn.ReLU() # 激活函数\n",
    "        self.flatten = nn.Flatten()# flatten 扁平的意思=> 将原来的高维数组换成只有 一行 的数组 列数是之前的各维度之积\n",
    "\n",
    "    # 定义网络构建函数\n",
    "    def construct(self,x):\n",
    "        # 构建前向网络\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x    \n",
    "\n",
    "#初始化网路\n",
    "net = LeNet5()\n",
    "for m in net.parameters_and_names():\n",
    "    print(m)\n",
    "    \n",
    "#定义超参\n",
    "epoch = 12\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    " \n",
    "#构建数据集\n",
    "sampler = ds.SequentialSampler(num_samples=128)\n",
    "dataset = ds.MnistDataset(DATA_DIR,sampler = sampler)\n",
    "\n",
    "#数据类型的转换\n",
    "type_cast_op_image = C.TypeCast(mstype.float32)\n",
    "type_cast_op_label = C.TypeCast(mstype.int32)\n",
    "\n",
    "#数据序列读取方式\n",
    "HWC2CHW = CV.HWC2CHW()\n",
    "\n",
    "#构建数据集\n",
    "dataset = dataset.map(operations=[type_cast_op_image,HWC2CHW],input_columns=\"image\")\n",
    "dataset = dataset.map(operations=type_cast_op_label,input_columns=\"label\")\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "print(\"\\n\")\n",
    "#传入定义的超参\n",
    "for p in net.trainable_params():\n",
    "    print(p)\n",
    "\n",
    "#函数\n",
    "optim = nn.SGD(params=net.trainable_params(),learning_rate=learning_rate)# 自动微分反向传播\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True,reduction='mean') # 交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入callback函数进行模型的保存\n",
    "from mindspore.train.callback import ModelCheckpoint\n",
    "ckpt_cb = ModelCheckpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据需求对checkpoint函数进行配置\n",
    "from mindspore.train.callback import ModelCheckpoint,CheckpointConfig\n",
    "\n",
    "# save_checkpoint_steps=32 每32次保存一次\n",
    "# keep_checkpoint_max=10 最多保留10个checkpoint\n",
    "\n",
    "config_cb = CheckpointConfig(save_checkpoint_steps=4,keep_checkpoint_max=10)\n",
    "\n",
    "# prefix = 'lenet5' 定义checkpoint文件前缀名称\n",
    "# directory 指定保存的地址 \n",
    "\n",
    "ckpt_cb = ModelCheckpoint(prefix='lenet5',directory=\"../quickStart01/model/\",config=config_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(6188:16984,MainProcess):2022-04-29-20:04:19.514.641 [mindspore\\train\\model.py:536] The CPU cannot support dataset sink mode currently.So the training process will be performed with dataset not sink.\n"
     ]
    }
   ],
   "source": [
    "#开始训练：输入训练轮次和训练数据集\n",
    "model = Model(net,loss_fn=loss,optimizer=optim)\n",
    "model.train(epoch=epoch,train_dataset=dataset,callbacks=ckpt_cb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1651218789000.png)\n",
    "\n",
    "其中  \n",
    "\n",
    "\\-graph.meta  是编译后的计算图\n",
    "\n",
    ".ckpt               是checkpoint文件，是权重文件\n",
    "\n",
    "![](1651218704000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型\n",
    "#### 进行 重训练 或者 推理\n",
    "要加载模型权重 需要 先创建 相同模型 的实例\n",
    "\n",
    "然后使用`load_checkpoint`和`load_param_into_net`方法加载参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建相同的模型实例\n",
    "from mindspore import load_checkpoint,load_param_into_net\n",
    "\n",
    "net0 = LeNet5()\n",
    "\n",
    "model0  = Model(net0,loss_fn = loss,metrics={\"accuracy\"})\n",
    "\n",
    "# 将模型参数存入字典\n",
    "param_dict = load_checkpoint(\"../quickStart01/model/lenet5_1-12_2.ckpt\")\n",
    "# print(param_dict)\n",
    "# 将参数加载到网络中去\n",
    "load_param_into_net(net0,param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型验证\n",
    "针对仅推理场景，把参数直接加载到网络中，以便后续的推理验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(6188:16984,MainProcess):2022-04-29-20:04:20.883.610 [mindspore\\train\\model.py:954] CPU cannot support dataset sink mode currently.So the evaluating process will be performed with dataset non-sink mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.1171875}\n"
     ]
    }
   ],
   "source": [
    "# create_custom_dataset\n",
    "TEST_DIR = DATA_DIR[:-5]+\"test\"\n",
    "# print(TEST_DIR)\n",
    "# 定义验证数据集\n",
    "sampler = ds.SequentialSampler(num_samples=128)\n",
    "dataset_eval = ds.MnistDataset(TEST_DIR,sampler=sampler)\n",
    "# dataset_eval = create_dataset(TEST_DIR,32,1)\n",
    "\n",
    "#数据类型的转换\n",
    "type_cast_op_image = C.TypeCast(mstype.float32)\n",
    "type_cast_op_label = C.TypeCast(mstype.int32)\n",
    "\n",
    "#数据序列读取方式\n",
    "HWC2CHW = CV.HWC2CHW()\n",
    "\n",
    "#构建数据集\n",
    "dataset_eval = dataset_eval.map(operations=[type_cast_op_image,HWC2CHW],input_columns=\"image\")\n",
    "dataset_eval = dataset_eval.map(operations=type_cast_op_label,input_columns=\"label\")\n",
    "dataset_eval = dataset_eval.batch(batch_size)\n",
    "\n",
    "# 调用eval()进行推理\n",
    "acc = model0.eval(dataset_eval)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习\n",
    "\n",
    "针对任务中断及微调（Fine-tuning）场景 可以加载网络参数和优化器参数到模型中。\n",
    "\n",
    "如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(6188:16984,MainProcess):2022-04-29-20:04:21.116.613 [mindspore\\train\\model.py:536] The CPU cannot support dataset sink mode currently.So the training process will be performed with dataset not sink.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mindspore\\core\\utils\\check_convert_utils.cc:664 _CheckTypeSame] For primitive[Conv2D], the input type must be same.\nname:[w]:Ref[Tensor(F32)].\nname:[x]:Tensor[UInt8].\n\nThe function call stack (See file 'f:\\000Codefield\\CODE_PY\\AI\\jupyterNotebook\\MindSpore01\\quickStart01\\rank_0\\om/analyze_fail.dat' for more details):\n# 0 In file D:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\wrap\\cell_wrapper.py(110)\n        out = self._backbone(data)\n              ^\n# 1 In file C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6188\\45943137.py(49)\n# 2 In file D:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\layer\\conv.py(267)\n        if self.has_bias:\n# 3 In file D:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\layer\\conv.py(266)\n        output = self.conv2d(x, self.weight)\n                 ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6188\\4195438053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 调用train()进行训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch00\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset00\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\train\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size)\u001b[0m\n\u001b[0;32m    772\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m                     \u001b[0mdataset_sink_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_sink_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 774\u001b[1;33m                     sink_size=sink_size)\n\u001b[0m\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msink_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjit_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\train\\model.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\train\\model.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size)\u001b[0m\n\u001b[0;32m    536\u001b[0m                 logger.warning(\"The CPU cannot support dataset sink mode currently.\"\n\u001b[0;32m    537\u001b[0m                                \"So the training process will be performed with dataset not sink.\")\n\u001b[1;32m--> 538\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_dataset_sink_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msink_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\train\\model.py\u001b[0m in \u001b[0;36m_train_process\u001b[1;34m(self, epoch, train_dataset, list_callback, cb_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mcb_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dataset_element\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[0mlist_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m                 \u001b[0mcb_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_scale_manager\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_scale_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_drop_overflow_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m                 raise ValueError(\"For 'Cell', it's not support hook function in graph mode, please use \"\n\u001b[0;32m    478\u001b[0m                                  \"context.set_context to set pynative mode.\")\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_and_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36mcompile_and_run\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m    804\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_auto_parallel_compile_and_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[0mnew_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInputs\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCell\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \"\"\"\n\u001b[1;32m--> 792\u001b[1;33m         \u001b[0m_cell_graph_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_parallel_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_auto_parallel_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompile_and_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\common\\api.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, obj, phase, do_convert, auto_parallel_mode, *args)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[0menable_ge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"enable_ge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_vm_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: mindspore\\core\\utils\\check_convert_utils.cc:664 _CheckTypeSame] For primitive[Conv2D], the input type must be same.\nname:[w]:Ref[Tensor(F32)].\nname:[x]:Tensor[UInt8].\n\nThe function call stack (See file 'f:\\000Codefield\\CODE_PY\\AI\\jupyterNotebook\\MindSpore01\\quickStart01\\rank_0\\om/analyze_fail.dat' for more details):\n# 0 In file D:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\wrap\\cell_wrapper.py(110)\n        out = self._backbone(data)\n              ^\n# 1 In file C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6188\\45943137.py(49)\n# 2 In file D:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\layer\\conv.py(267)\n        if self.has_bias:\n# 3 In file D:\\Anaconda3\\envs\\mindsp161\\lib\\site-packages\\mindspore\\nn\\layer\\conv.py(266)\n        output = self.conv2d(x, self.weight)\n                 ^\n"
     ]
    }
   ],
   "source": [
    "# 设置训练轮次\n",
    "\n",
    "epoch00 = 1\n",
    "\n",
    "# 定义训练数据集\n",
    "dataset00 = ds.MnistDataset(DATA_DIR,sampler = sampler) \n",
    "\n",
    "# 调用train()进行训练\n",
    "model0.train(epoch00,dataset00)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e203e762bfffed2ed95f356b7746f45c38e9111b20c3e823e88c83c42bbc40aa"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('mindsp161')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
